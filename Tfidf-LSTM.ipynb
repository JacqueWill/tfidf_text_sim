{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae409563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "557e0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bda5d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DBPEDIA_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fb51279",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                             strip_accents='unicode',\n",
    "                             norm='l2',\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4b0f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in range(len(df)):\n",
    "  string = df['text'][i]            \n",
    "  string = vectorizer.build_preprocessor()(string.lower()) \n",
    "  string = vectorizer.build_tokenizer()(string.lower())\n",
    "  X_train.append(' '.join(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d179f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"DBPEDIA_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "526ceed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(len(df_test)):\n",
    "  string = df_test['text'][i]\n",
    "  string = vectorizer.build_preprocessor()(string.lower())\n",
    "  string=vectorizer.build_tokenizer()(string.lower())\n",
    "  X_test.append(' '.join(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab0f0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0891b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cdecea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "df['l1'] = LE.fit_transform(df['l1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54961821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['l1'] = LE.transform(df_test['l1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "202b3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['l1']\n",
    "y_test = df_test['l1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ca624327",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 846. GiB for an array with shape (240942, 471243) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_train\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mtodense()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:864\u001b[0m, in \u001b[0;36mspmatrix.todense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtodense\u001b[39m(\u001b[38;5;28mself\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m    Return a dense matrix representation of this matrix.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m        `numpy.matrix` object that shares the same memory.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asmatrix(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:1039\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1039\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:1202\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 846. GiB for an array with shape (240942, 471243) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train = X_train.todense()\n",
    "y_train=y_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "936ad7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee69417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tf-nightly\n",
      "  Downloading tf_nightly-2.12.0.dev20221104-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "Collecting tf-nightly-intel==2.12.0-dev20221104\n",
      "  Downloading tf_nightly_intel-2.12.0.dev20221104-cp39-cp39-win_amd64.whl (177.7 MB)\n",
      "     ------------------------------------ 177.7/177.7 MB 451.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (22.10.26)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (4.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (61.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (0.27.0)\n",
      "Collecting tb-nightly~=2.11.0.a\n",
      "  Downloading tb_nightly-2.11.0a20221104-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 518.8 kB/s eta 0:00:00\n",
      "Collecting keras-nightly~=2.12.0.dev\n",
      "  Downloading keras_nightly-2.12.0.dev2022110407-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 363.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.21.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.16.0)\n",
      "Collecting tf-estimator-nightly~=2.12.0.dev\n",
      "  Downloading tf_estimator_nightly-2.12.0.dev2022110408-py2.py3-none-any.whl (439 kB)\n",
      "     ------------------------------------ 439.4/439.4 kB 232.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (3.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.42.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (3.19.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (14.0.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from packaging->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\khair\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.11.0.a->tf-nightly-intel==2.12.0-dev20221104->tf-nightly) (3.2.2)\n",
      "Installing collected packages: tf-estimator-nightly, keras-nightly, tb-nightly, tf-nightly-intel, tf-nightly\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\khair\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\tf2tensorrt\\\\_pywrap_py_utils.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5c313c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "53f39f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(471243,256 ,input_length = 471243))\n",
    "model.add(LSTM(units=128, return_sequences = True))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(LSTM(units=6, return_sequences=True))\n",
    "model.add(LSTM(units=1, return_sequences=True, name='output'))\n",
    "model.compile(loss=tf.keras.losses.KLDivergence(),optimizer='sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d2333f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 471243, 256)       120638208 \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 471243, 128)       197120    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 471243, 64)        8256      \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 471243, 6)         1704      \n",
      "                                                                 \n",
      " output (LSTM)               (None, 471243, 1)         32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,845,320\n",
      "Trainable params: 120,845,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99c3af2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khair\\AppData\\Local\\Temp\\ipykernel_12824\\1238351121.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=batch_generator(X_train, y_train, 32),\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'key of type tuple not found and not a MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2495\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2496\u001b[0m \n\u001b[0;32m   2497\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2498\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2499\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2501\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2504\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2505\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2506\u001b[0m )\n\u001b[1;32m-> 2507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2509\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2519\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2521\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36mbatch_generator\u001b[1;34m(X, y, batch_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m index_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])[batch_size\u001b[38;5;241m*\u001b[39mi:batch_size\u001b[38;5;241m*\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)]       \n\u001b[0;32m      5\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X[index_batch,:]\u001b[38;5;241m.\u001b[39mtodense()\n\u001b[1;32m----> 6\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m(np\u001b[38;5;241m.\u001b[39marray(X_batch),y_batch)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:984\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    981\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[1;32m--> 984\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:999\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    995\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing a Series with DataFrame is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported, use the appropriate DataFrame column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m     )\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 999\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key):\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;66;03m# e.g. scalars that aren't recognized by lib.is_scalar, GH#32684\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1034\u001b[0m, in \u001b[0;36mSeries._get_values_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m-> 1034\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey of type tuple not found and not a MultiIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# If key is contained, would have returned by now\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m indexer, new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc_level(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=batch_generator(X_train, y_train, 32),\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cdff6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f2c22ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    n_batches_for_epoch = X.shape[0]//batch_size\n",
    "    for i in range(n_batches_for_epoch):\n",
    "        index_batch = range(X.shape[0])[batch_size*i:batch_size*(i+1)]       \n",
    "        X_batch = X[index_batch,:].todense()\n",
    "        y_batch = y[index_batch,:]\n",
    "        yield(np.array(X_batch),y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97d63990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nTypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 513, in py_method\n    flat_out = tf.py_function(py_method, [indices], flat_dtypes)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 513, in <listcomp>\n    flat_out = tf.py_function(py_method, [indices], flat_dtypes)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 509, in slice_array\n    )\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_43327]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nTypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 513, in py_method\n    flat_out = tf.py_function(py_method, [indices], flat_dtypes)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 513, in <listcomp>\n    flat_out = tf.py_function(py_method, [indices], flat_dtypes)\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 509, in slice_array\n    )\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"C:\\Users\\khair\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_43327]"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500fd4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
